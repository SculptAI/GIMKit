{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c21021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "from gimkit import guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe80bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the llm_request using any framework you like\n",
    "\n",
    "GIM_MODEL_NAME = \"/root/autodl-tmp/GIM/artifacts/09191-gim-sft-2/sft-gim\"\n",
    "OPEN_API_KEY = \"EMPTY\"\n",
    "OPENAI_API_BASE = \"http://localhost:8000/v1\"\n",
    "\n",
    "\n",
    "def llm_request(query: str) -> str:\n",
    "    client = OpenAI(\n",
    "        api_key=OPEN_API_KEY,\n",
    "        base_url=OPENAI_API_BASE,\n",
    "    )\n",
    "    completion = client.completions.create(\n",
    "        model=GIM_MODEL_NAME, prompt=query, max_tokens=8000, presence_penalty=1, seed=0\n",
    "    )\n",
    "    return completion.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b520c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 24 puzzle\n",
    "\n",
    "g = guide()\n",
    "\n",
    "puzzle_24 = \"\"\"2 {} 4 {} 6 {} 2 = 24\"\"\".format(\n",
    "    *[g(desc=\"a single math operator\") for _ in range(3)]\n",
    ")\n",
    "query = g.standardize(puzzle_24)\n",
    "\n",
    "response = llm_request(query)\n",
    "result = g.parse(query, response.strip())\n",
    "\n",
    "print(result.tags[0].content, result.tags[1].content, result.tags[2].content)\n",
    "print(result.infill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece99a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Chinese Chain-of-Thought QA example\n",
    "\n",
    "g = guide()\n",
    "\n",
    "a_chinese_cot_qa = \"\"\"对于淀粉和纤维素两种物质，下列说法正确的是____\n",
    "A. 两者都能水解，且水解的最终产物相同\n",
    "B. 两者含C、H、O三种元素的质量分数相同，且互为同分异构体\n",
    "C. 它们都属于糖类，且都是溶于水的高分子化合物\n",
    "D. 都可 用$\\\\left ( C_6H_6O_5\\\\right )_n$表示，但淀粉能发生银镜反应，而纤维素不能\n",
    "\n",
    "让我们一步步思考\n",
    "1. {}\n",
    "2. {}\n",
    "3. {}\n",
    "4. {}\n",
    "5. {}\n",
    "6. {}\n",
    "所以答案是：{}\n",
    "\"\"\".format(*([g(desc=\"一个思考步骤\") for _ in range(6)] + [g(desc=\"选项对应的文本\")]))\n",
    "\n",
    "query = g.standardize(a_chinese_cot_qa)\n",
    "print(query)\n",
    "\n",
    "response = llm_request(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b34a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer multiple questions in the same prompt\n",
    "g = guide()\n",
    "\n",
    "questions = f\"\"\"Mixing red and blue results in {g(desc=\"Use hexadecimal color like\")}\"\"\"\n",
    "query = g.standardize(questions)\n",
    "print(query)\n",
    "response = llm_request(query)\n",
    "print(response)\n",
    "result = g.parse(query, response)\n",
    "print(result.infill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e0e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table completion\n",
    "\n",
    "g = guide()\n",
    "\n",
    "question = f\"\"\"| Application Scenario     | Description                                                   |\n",
    "|--------------------------|-------------------------------------------------------------|\n",
    "| {g()}       | Achieve automated lighting control through protocols like Wi-Fi or Zigbee, enhancing convenience and energy efficiency. |\n",
    "| Smart City - Traffic Management | Optimize traffic flow using 5G networks and AI video analysis, improving traffic safety and efficiency. |\n",
    "| Industrial IoT - Maintenance    | Use IIoT platforms and machine learning for predictive maintenance, reducing downtime and maintenance costs. |\n",
    "| Agriculture - Precision Farming  | {g()} |\n",
    "| Healthcare - Remote Monitoring   | Real-time monitoring of patient health status through wearable devices, supporting telemedicine and personalized treatment. |\n",
    "| {g(desc=\"Scenario\")} | {g(desc=\"Description\")} |\n",
    "| Environmental Protection - Air Quality | Deploy miniature air quality sensors to monitor and warn of air pollution events, protecting public health. |\"\"\"\n",
    "\n",
    "query = g.standardize(question)\n",
    "print(query)\n",
    "response = llm_request(query)\n",
    "print(response)\n",
    "result = g.parse(query, response)\n",
    "print(result.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd78a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data synthesis\n",
    "\n",
    "g = guide()\n",
    "\n",
    "question = f\"\"\"Complete the algorithm profile in TOML:\n",
    "\n",
    "[algorithm_profile]\n",
    "name = {g(desc=\"an any algorithm name\")}\n",
    "type = {g(desc=\"list[str] type; 4 items\")}\n",
    "performance.time_complexity: {g(desc=\"str type; use LaTeX expression\")},\n",
    "performance.space_complexity: {g(desc=\"str type; use LaTeX expression\")}\"\"\"\n",
    "\n",
    "query = g.standardize(question)\n",
    "print(query)\n",
    "response = llm_request(query)\n",
    "print(response)\n",
    "result = g.parse(query, response)\n",
    "print(result.infill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c4ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge graph extraction\n",
    "\n",
    "g = guide()\n",
    "\n",
    "question = f\"\"\"## Content\n",
    "\n",
    "We were both young when I first saw you\n",
    "I close my eyes and the flashback starts\n",
    "I'm standin' there\n",
    "On a balcony in summer air\n",
    "See the lights, see the party, the ball gowns\n",
    "See you make your way through the crowd\n",
    "And say, \"Hello\"\n",
    "Little did I know\n",
    "That you were Romeo, you were throwin' pebbles\n",
    "And my daddy said, \"Stay away from Juliet\"\n",
    "And I was cryin' on the staircase\n",
    "Beggin' you, \"Please don't go, \" and I said\n",
    "Romeo, take me somewhere we can be alone\n",
    "I'll be waiting, all there's left to do is run\n",
    "You'll be the prince and I'll be the princess\n",
    "It's a love story, baby, just say, \"Yes\"\n",
    "\n",
    "## Extraction\n",
    "\n",
    "Extract knowledge graph triplets (head, relation, tail) from the content.\n",
    "\n",
    "1. ({g()}, {g()}, {g()})\n",
    "2. ({g()}, {g()}, {g()})\n",
    "3. ({g()}, {g()}, {g()})\n",
    "4. ({g()}, {g()}, {g()})\n",
    "5. ({g()}, {g()}, {g()})\n",
    "6. ({g()}, {g()}, {g()})\n",
    "7. ({g()}, {g()}, {g()})\n",
    "8. ({g()}, {g()}, {g()})\n",
    "9. ({g()}, {g()}, {g()})\n",
    "\"\"\"\n",
    "\n",
    "query = g.standardize(question)\n",
    "print(query)\n",
    "response = llm_request(query)\n",
    "print(response)\n",
    "result = g.parse(query, response)\n",
    "print(result.infill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c522548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code completion example from (Fried, et al. 2022) InCoder\n",
    "\n",
    "g = guide()\n",
    "\n",
    "code2docstring = '''def count_words(filename):\n",
    "    \"\"\"{}\"\"\"\n",
    "    counts = Counter()\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            words = line.split(' ')\n",
    "            counts.update(words)\n",
    "    return counts\n",
    "'''\n",
    "\n",
    "query = g.standardize(code2docstring)\n",
    "print(query)\n",
    "response = llm_request(query)\n",
    "print(response)\n",
    "result = g.parse(query, response)\n",
    "print(result.infill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f218d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also from (Fried, et al. 2022) InCoder\n",
    "\n",
    "g = guide()\n",
    "\n",
    "docstring2code = '''\n",
    "def {}:\n",
    "    \"\"\" Count the number of occurrences of each word in the file. \"\"\"\n",
    "    {}\n",
    "'''\n",
    "\n",
    "query = g.standardize(docstring2code)\n",
    "print(query)\n",
    "response = llm_request(query)\n",
    "print(response)\n",
    "result = g.parse(query, response)\n",
    "print(result.infill())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GIM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
